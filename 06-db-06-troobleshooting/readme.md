## Задача 1

_Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать._ 

_Вы как инженер поддержки решили произвести данную операцию:_
- _напишите список операций, которые вы будете производить для остановки запроса пользователя_
- _предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB_

Для прерывания операций в MondoDB существует метод `db.killOp()`, которому нужно передать id прерываемой операции. Чтобы узнать её id, можно воспользоваться методом `db.currentOp()`. Например, можно найти все активные транзакции, активные дольше трех минут и выполняемые от пользователя, который к нам обратился.
```shell
db.currentOp(
  {
    "active" : true,
    "runBy" : [
      {
        "user" : "name_of_the_user",
        "db" : "name_of_the_db"
      }
    ],
    "secs_running" : { "$gt" : 180 },
    "ns" : "<database>.<collection>"
  }
)
```

После получения id мы сможем передать их в метод `db.killOp()`:
```shell
db.killOp(<opid_1>)
db.killOp(<opid_2>)
<...>
```

Варианты решения проблем с зависающими запросами.
1. Если позволяет архитектура, использование Free Monitoring, с его помощью можно мониторить Operation Execution Times.
2. Методом `cursor.explain()` можно получить информацию о плане запроса и поиска возможностей его оптимизации. В режиме `queryPlanner` (режим по умолчанию) метод запускает оптимизатор запроса для поиска наилучшего пути выполнения: MongoDB runs the query optimizer to choose the winning plan for the operation under evaluation. ([Источник](https://www.mongodb.com/docs/v6.0/reference/method/cursor.explain/#mongodb-method-cursor.explain))
3. Также можно использовать метод `cursor.maxTimeMS(<milliseconds>)` для установки верхнего ограничения в миллисекундах для времени выполнения запроса. Если запрос выполняется дольше установленного ограничения, он будет завершен тем же механизмом, который использует `db.killOp()`.

## Задача 2

_Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса._ 

_При масштабировании сервиса до N реплик вы увидели, что:_
- _сначала рост отношения записанных значений к истекшим_
- _Redis блокирует операции записи_

_Как вы думаете, в чем может быть проблема?_

В идеале, хорошо бы заранее активировать Latency Monitoring, чтобы иметь возможность изучить данные. Активировать его можно так: `CONFIG SET latency-monitor-threshold N`, где `N` — максимально допустимое время для исполнения команды в миллисекундах. В монитор попадут только операции, время выполнения которых превышает `N`.

Также можно активировать программный watchdog: `CONFIG SET watchdog-period N`, где `N`, опять же, время в миллисекундах (минимум 200).

Потом я бы измерил latency, чтобы понять, какие задержки вообще происходят: `redis-cli --latency -h 'host' -p 'port'`.

Потом я бы проверил, не выполняются ли какие-то из "медленных команд", воспользовавшись `SLOWLOG GET` (`redis-cli SLOWLOG GET`). Команда возвращает в хронологическом порядке все запросы (если в явном виде не указать выводимое количество), которые по времени исполнения превышают выделенное им допустимое время исполнения.

## Задача 3

_Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:_
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

_Как вы думаете, почему это начало происходить и как локализовать проблему?_

_Какие пути решения данной проблемы вы можете предложить?_

С точки зрения документации, есть четыре самых частных причины такой ошибки.

1. Проблемы с сетью и подключением к серверу. Чисто теоретически как первую линию решения проблемы на всякий случай можно проверить, все ли в порядке с сетью, но в целом мне это кажется менее вероятным вариантом из-за того, что ошибка типа during query.
2. Возможно, запрос настолько пространный, а БД и количество данных настолько большие, что будут читаться и отправляться в качестве результата запроса миллионы строк. Если так и должно быть, мы можем увеличить значение переменной `net_read_timeout` (в секундах) — это время, после которого при чтении сервером с клиента или при записи в клиента соединение будет разорвано. При пространном запросе и/или при больших объемах данных нам нужно уеличивать значение этой переменной, потому что требуется все больше времени для чтения/записи данных и обработки запроса на сервере.
3. Реже, но это может происходить, когда клиент пытается установить первичное соединение с сервером. Если у нас плохое сетевое соединение или сервер физически сильно удален от клиента, коннект длится дольше, чем ему позволяет переменная `connect_timeout`. Когда мы превышаем это значение, соединение разрывается. Мы можем увеличить значение и ждать connect packet дольше.
4. Также возможна проблема с BLOB'ом, но мне это кажется уже очень изощренной и очень ен частой проблемой. :)

Говоря в общем, скорее всего, происходит превышение времени ожидания во время какой-то операции. Стоит смотреть, все ли в порядке с сетевым соединением и с timeout-переменными вроде `connect_timeout`, `interactive_timeout`, `wait_timeout`. Возможно, время ожидания превышает допустимые таймауты и их нужно просто увеличить.

# Задача 4

_Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL._

_После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:_

`postmaster invoked oom-killer`

_Как вы думаете, что происходит?_

_Как бы вы решили данную проблему?_

Это указывает на нехватку памяти для PostgreSQL.

Стоит оценить, действительно ли этот перерасход памяти происходит из-за объема данных/количества запросов или какие-то данные хранятся/плодятся нерационально.

Решение в лоб — добавить памяти виртуальной машине, но это всегда довольно опасно, потому что если память выедается из-за не оптимизированных процессов, увеличение количества памяти не поможет. 